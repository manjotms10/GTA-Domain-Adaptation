{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "import itertools\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for project\n",
    "proj_root = \"/datasets/home/73/673/h6gupta/Project/\"\n",
    "\n",
    "# Root directory for dataset\n",
    "data_root = \"/datasets/home/73/673/h6gupta/Project/6_train/images/\"\n",
    "\n",
    "# Number of images in the directory\n",
    "num_images = 23418\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 16\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.00005\n",
    "\n",
    "# Alpha hyperparam for RMS optimizers\n",
    "alpha = 0.9\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = torch.cuda.device_count()\n",
    "\n",
    "# Device to run on\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Parameters:\n",
    "        \n",
    "        '''\n",
    "        self.device = device\n",
    "        self.data_path = data_root\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_test = pickle.load(open( \"train_test.p\", \"rb\"))\n",
    "        self.names = self.train_test['train']\n",
    "        self.data_transforms = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(image_size),\n",
    "                torchvision.transforms.CenterCrop(image_size),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "    \n",
    "    def image_loader(self, image_name):\n",
    "        \"\"\"load image, returns cuda tensor\"\"\"\n",
    "        image = Image.open(image_name)\n",
    "        image = self.data_transforms(image).float()\n",
    "        image = torch.autograd.Variable(image, requires_grad=False)\n",
    "        image = image.unsqueeze(0)  # this is for VGG, may not be needed for ResNet\n",
    "        return image[0].to(self.device)  # assumes that you're using GPU\n",
    "\n",
    "    def show(self, img):\n",
    "        npimg = img.cpu().detach().numpy()\n",
    "        npimg = np.transpose(npimg, (1,2,0))\n",
    "        if npimg.shape[2] == 3:\n",
    "            plt.imshow(npimg)\n",
    "        else:\n",
    "            plt.imshow(npimg[:,:,0], cmap='gray')\n",
    "            \n",
    "    def imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.cpu().detach().numpy()\n",
    "        plt.figure(figsize = (10,2))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), aspect='auto')\n",
    "\n",
    "    def data_generator(self):\n",
    "        root = self.data_path\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        images_dir = root + 'real_A/'\n",
    "        labels_dir = root + 'fake_B/'\n",
    "\n",
    "        while True:\n",
    "            x, y = [], []\n",
    "            idx = np.random.choice(self.names, batch_size)\n",
    "            for i in range(idx.shape[0]):\n",
    "                x.append(self.image_loader(images_dir + idx[i]))\n",
    "                y.append(self.image_loader(labels_dir + idx[i]))\n",
    "            yield torch.stack(x), torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # Convolution layers\n",
    "        \n",
    "        # input is (nc) x 256 x 256\n",
    "        self.conv1 = nn.Conv2d(nc, ngf, 4, 2, 1, bias=True)\n",
    "        self.lr1 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf) x 128 x 128\n",
    "        self.conv2 = nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf*2)\n",
    "        self.lr2 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*2) x 64 x 64\n",
    "        self.conv3 = nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf*4)\n",
    "        self.lr3 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*4) x 32 x 32\n",
    "        self.conv4 = nn.Conv2d(ngf*4, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr4 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 16 x 16\n",
    "        self.conv5 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn5 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr5 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 8 x 8\n",
    "        self.conv6 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr6 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        self.conv7 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr7 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 2 x 2\n",
    "        self.conv8 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*8)\n",
    "        self.r8 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Transpose Convolutional Layers\n",
    "        \n",
    "        # input is (ngf*8) x 1 x 1\n",
    "        self.tr_conv1 = nn.ConvTranspose2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r1 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 2 x 2\n",
    "        self.tr_conv2 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn2 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r2 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 4 x 4\n",
    "        self.tr_conv3 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn3 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r3 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 8 x 8\n",
    "        self.tr_conv4 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn4 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r4 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 16 x 16\n",
    "        self.tr_conv5 = nn.ConvTranspose2d((ngf*8)*2, ngf*4, 4, 2, 1, bias=True)\n",
    "        self.tr_bn5 = nn.BatchNorm2d(ngf*4)\n",
    "        self.tr_r5 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*4)*2 x 32 x 32\n",
    "        self.tr_conv6 = nn.ConvTranspose2d((ngf*4)*2, ngf*2, 4, 2, 1, bias=True)\n",
    "        self.tr_bn6 = nn.BatchNorm2d(ngf*2)\n",
    "        self.tr_r6 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*2)*2 x 64 x 64\n",
    "        self.tr_conv7 = nn.ConvTranspose2d((ngf*2)*2, ngf, 4, 2, 1, bias=True)\n",
    "        self.tr_bn7 = nn.BatchNorm2d(ngf)\n",
    "        self.tr_r7 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf)*2 x 128 x 128\n",
    "        self.tr_conv8 = nn.ConvTranspose2d((ngf)*2, nc, 4, 2, 1, bias=True)\n",
    "        self.out = nn.Tanh()\n",
    "        # state size. (nc) x 256 x 256\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.bn2(self.conv2(self.lr1(c1)))\n",
    "        c3 = self.bn3(self.conv3(self.lr2(c2)))\n",
    "        c4 = self.bn4(self.conv4(self.lr3(c3)))\n",
    "        c5 = self.bn5(self.conv5(self.lr4(c4)))\n",
    "        c6 = self.bn6(self.conv6(self.lr5(c5)))\n",
    "        c7 = self.bn7(self.conv7(self.lr6(c6)))\n",
    "        c8 = self.bn8(self.conv8(self.lr7(c7)))\n",
    "        \n",
    "        t1 = self.tr_bn1(self.tr_conv1(self.r8(c8)))\n",
    "        t1 = torch.cat((t1, c7), dim=1)\n",
    "        t2 = self.tr_bn2(self.tr_conv2(self.tr_r1(t1)))\n",
    "        t2 = torch.cat((t2, c6), dim=1)\n",
    "        t3 = self.tr_bn3(self.tr_conv3(self.tr_r2(t2)))\n",
    "        t3 = torch.cat((t3, c5), dim=1)\n",
    "        t4 = self.tr_bn4(self.tr_conv4(self.tr_r3(t3)))\n",
    "        t4 = torch.cat((t4, c4), dim=1)\n",
    "        t5 = self.tr_bn5(self.tr_conv5(self.tr_r4(t4)))\n",
    "        t5 = torch.cat((t5, c3), dim=1)\n",
    "        t6 = self.tr_bn6(self.tr_conv6(self.tr_r5(t5)))\n",
    "        t6 = torch.cat((t6, c2), dim=1)\n",
    "        t7 = self.tr_bn7(self.tr_conv7(self.tr_r6(t6)))\n",
    "        t7 = torch.cat((t7, c1), dim=1)\n",
    "        t8 = self.tr_conv8(self.tr_r7(t7))\n",
    "        t8 = self.out(t8)\n",
    "        return t8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a = Generator().to(device)\n",
    "gen_b = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # input is (nc) x 256 x 256\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 128 x 128\n",
    "            nn.MaxPool2d((2, 2)), \n",
    "            \n",
    "            # state size. (ndf) x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 32 x 32\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, ndf * 8, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        \n",
    "        self.flat = nn.Linear(ndf * 8 * 2 * 2, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.flat(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_a = Discriminator().to(device)\n",
    "dis_b = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochTracker():\n",
    "    def __init__(self, in_file):\n",
    "        self.epoch = 0\n",
    "        self.iter = 0\n",
    "        self.in_file = in_file\n",
    "        self.file_exists = os.path.isfile(in_file)\n",
    "        if self.file_exists:\n",
    "            with open(in_file, 'r') as f: \n",
    "                d = f.read() \n",
    "                a, b = d.split(\";\")\n",
    "                self.epoch = int(a)\n",
    "                self.iter = int(b)\n",
    "    \n",
    "    def write(self, epoch, iteration):\n",
    "        self.epoch = epoch\n",
    "        self.iter = iteration\n",
    "        data = \"{};{}\".format(self.epoch, self.iter)\n",
    "        with open(self.in_file, 'w') as f:\n",
    "            f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (13): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (flat): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataParallel for more than 1 gpu\n",
    "# gen_a = nn.DataParallel(gen_a, list(range(ngpu)))\n",
    "# dis_a = nn.DataParallel(dis_a, list(range(ngpu)))\n",
    "# gen_b = nn.DataParallel(gen_b, list(range(ngpu)))\n",
    "# dis_b = nn.DataParallel(dis_b, list(range(ngpu)))\n",
    "\n",
    "gen_a.apply(weights_init_normal)\n",
    "dis_a.apply(weights_init_normal)\n",
    "gen_b.apply(weights_init_normal)\n",
    "dis_b.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()\n",
    "\n",
    "optim_gen = torch.optim.RMSprop(itertools.chain(gen_a.parameters(), gen_b.parameters()), lr, alpha)\n",
    "optim_dis = torch.optim.RMSprop(itertools.chain(dis_a.parameters(), dis_b.parameters()), lr, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_interval = 25\n",
    "checkpoint_interval = 500\n",
    "file_prefix = proj_root + 'saved_models/dual_gans_semi/'\n",
    "\n",
    "e_tracker = EpochTracker(file_prefix + 'epoch.txt')\n",
    "\n",
    "if(e_tracker.file_exists):\n",
    "    gen_a.load_state_dict(torch.load(file_prefix + 'generator_a.pth'))\n",
    "    dis_a.load_state_dict(torch.load(file_prefix + 'discriminator_a.pth'))\n",
    "    gen_b.load_state_dict(torch.load(file_prefix + 'generator_b.pth'))\n",
    "    dis_b.load_state_dict(torch.load(file_prefix + 'discriminator_b.pth'))\n",
    "    \n",
    "for epoch in range(e_tracker.epoch, num_epochs):\n",
    "    for i in range(num_images // batch_size):\n",
    "        if epoch == e_tracker.epoch and i < e_tracker.iter:\n",
    "            continue\n",
    "            \n",
    "        x, y = next(data.data_generator())\n",
    "        real_a = Variable(x).to(device)\n",
    "        real_b = Variable(y).to(device)     \n",
    "        valid = Variable(torch.ones((real_a.size(0), 1)), requires_grad=False).to(device)\n",
    "        fake = Variable(torch.zeros((real_a.size(0), 1)), requires_grad=False).to(device)\n",
    "        \n",
    "        # Training Discriminator A with real_A batch\n",
    "        optim_dis.zero_grad();\n",
    "        pred_real_dis_a = dis_a(real_a).view(-1, 1)\n",
    "        err_real_dis_a = criterion(pred_real_dis_a, valid)\n",
    "        \n",
    "        # Training Discriminator B with real_B batch\n",
    "        pred_real_dis_b = dis_b(real_b).view(-1, 1)\n",
    "        err_real_dis_b = criterion(pred_real_dis_b, valid)\n",
    "        \n",
    "        # Training Discriminator B with fake_B batch of Generator A\n",
    "        fake_b = gen_a(real_a)\n",
    "        pred_fake_dis_b = dis_b(fake_b.detach()).view(-1, 1)\n",
    "        err_fake_dis_b = criterion(pred_fake_dis_b, fake)\n",
    "        \n",
    "        # Training Discriminator A with fake_A batch of Generator B\n",
    "        fake_a = gen_b(real_b)\n",
    "        pred_fake_dis_a = dis_a(fake_a.detach()).view(-1, 1)\n",
    "        err_fake_dis_a = criterion(pred_fake_dis_a, fake)\n",
    "        \n",
    "        # Update params of Discriminator A and B\n",
    "        err_dis_a = err_real_dis_a + err_fake_dis_a\n",
    "        err_dis_b = err_real_dis_b + err_fake_dis_b\n",
    "        err_dis = err_dis_a + err_dis_b\n",
    "        err_dis.backward()\n",
    "        optim_dis.step()\n",
    "        \n",
    "        # Train and update Generator A based on Discriminator B's prediction\n",
    "        optim_gen.zero_grad()\n",
    "        fake_b_gen = gen_a(fake_a)\n",
    "        pred_out_dis_b = dis_b(fake_b_gen).view(-1, 1)\n",
    "        err_gen_a_pred = criterion(pred_out_dis_b, valid)\n",
    "        err_gen_a_pixel_supervised = criterion_pixelwise(fake_b[:3, :, :, :], real_b[:3, :, :, :])\n",
    "        err_gen_a_pixel_recon = criterion_pixelwise(fake_b_gen, real_b)\n",
    "        err_gen_a = err_gen_a_pred + err_gen_a_pixel_supervised + err_gen_a_pixel_recon\n",
    "        \n",
    "        # Train and update Generator B based on Discriminator A's prediction\n",
    "        fake_a_gen = gen_b(fake_b)\n",
    "        pred_out_dis_a = dis_a(fake_a_gen).view(-1, 1)\n",
    "        err_gen_b_pred = criterion(pred_out_dis_a, valid)\n",
    "        err_gen_b_pixel_supervised = criterion_pixelwise(fake_a[:3, :, :, :], real_a[:3, :, :, :]) \n",
    "        err_gen_b_pixel_recon = criterion_pixelwise(fake_a_gen, real_a)\n",
    "        err_gen_b = err_gen_b_pred + err_gen_b_pixel_supervised + err_gen_b_pixel_recon\n",
    "        \n",
    "        # Update params of Generator A and B\n",
    "        err_gen = err_gen_a + err_gen_b\n",
    "        err_gen.backward()\n",
    "        optim_gen.step()\n",
    "        \n",
    "        # Print statistics and save checkpoints\n",
    "        print(\"\\r[Epoch %d/%d] [Batch %d/%d] [D_A loss: %f] [D_B loss: %f] [G_A loss: %f, G_B loss: %f]\" %\n",
    "                                                        (epoch, num_epochs,\n",
    "                                                        i, num_images//batch_size,\n",
    "                                                        err_dis_a.item(), err_dis_b.item(), \n",
    "                                                        err_gen_a.item(), err_gen_b.item()))\n",
    "\n",
    "        if i % sample_interval == 0:\n",
    "            img_sample = torch.cat((real_a.data, fake_a.data, real_b.data, fake_b.data), -2)\n",
    "            save_image(img_sample, proj_root + 'saved_images/dual_gans_semi/%d_%d.png' % (epoch, i), nrow=5, normalize=True)\n",
    "\n",
    "            torch.save(gen_a.state_dict(), proj_root + 'saved_models/dual_gans_semi/generator_a.pth')\n",
    "            torch.save(gen_b.state_dict(), proj_root + 'saved_models/dual_gans_semi/generator_b.pth')\n",
    "            torch.save(dis_a.state_dict(), proj_root + 'saved_models/dual_gans_semi/discriminator_a.pth')\n",
    "            torch.save(dis_b.state_dict(), proj_root + 'saved_models/dual_gans_semi/discriminator_b.pth')\n",
    "            e_tracker.write(epoch, i)\n",
    "            \n",
    "        torch.save(gen_a.state_dict(), proj_root + 'saved_models/dual_gans_semi/generator_a.pth_%d_%d.pth' % (epoch, i))\n",
    "        torch.save(gen_b.state_dict(), proj_root + 'saved_models/dual_gans_semi/generator_b.pth_%d_%d.pth' % (epoch, i))\n",
    "        torch.save(dis_a.state_dict(), proj_root + 'saved_models/dual_gans_semi/discriminator_a.pth_%d_%d.pth' % (epoch, i))\n",
    "        torch.save(dis_b.state_dict(), proj_root + 'saved_models/dual_gans_semi/discriminator_b.pth_%d_%d.pth' % (epoch, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
