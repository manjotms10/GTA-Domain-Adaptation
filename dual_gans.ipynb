{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for project\n",
    "proj_root = \"/datasets/home/32/232/tdobhal/Project/\"\n",
    "\n",
    "# Root directory for dataset\n",
    "data_root = \"/datasets/home/32/232/tdobhal/Project/6_train/images/\"\n",
    "\n",
    "# Number of images in the directory\n",
    "num_images = 23418\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 16\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size using a transformer.\n",
    "image_size = 256\n",
    "\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "# Learning rate for optimizers\n",
    "lr = 0.00005\n",
    "\n",
    "# Alpha hyperparam for RMS optimizers\n",
    "alpha = 0.9\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = torch.cuda.device_count()\n",
    "\n",
    "# Device to run on\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Parameters:\n",
    "        \n",
    "        '''\n",
    "        self.device = device\n",
    "        self.data_path = data_root\n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.train_names = glob.glob(self.data_path + 'real_A/*')\n",
    "        self.names = [self.train_names[i].split('/')[-1] for i in range(len(self.train_names))]\n",
    "        self.data_transforms = torchvision.transforms.Compose([\n",
    "                torchvision.transforms.Resize(image_size),\n",
    "                torchvision.transforms.CenterCrop(image_size),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "    \n",
    "    def image_loader(self, image_name):\n",
    "        \"\"\"load image, returns cuda tensor\"\"\"\n",
    "        image = Image.open(image_name)\n",
    "        image = self.data_transforms(image).float()\n",
    "        image = torch.autograd.Variable(image, requires_grad=True)\n",
    "        image = image.unsqueeze(0)  # this is for VGG, may not be needed for ResNet\n",
    "        return image[0].to(self.device)  # assumes that you're using GPU\n",
    "\n",
    "    def show(self, img):\n",
    "        npimg = img.cpu().detach().numpy()\n",
    "        npimg = np.transpose(npimg, (1,2,0))\n",
    "        if npimg.shape[2] == 3:\n",
    "            plt.imshow(npimg)\n",
    "        else:\n",
    "            plt.imshow(npimg[:,:,0], cmap='gray')\n",
    "            \n",
    "    def imshow(self, img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.cpu().detach().numpy()\n",
    "        plt.figure(figsize = (10,2))\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)), aspect='auto')\n",
    "\n",
    "    def data_generator(self):\n",
    "        root = self.data_path\n",
    "        batch_size = self.batch_size\n",
    "        \n",
    "        images_dir = root + 'real_A/'\n",
    "        labels_dir = root + 'fake_B/'\n",
    "\n",
    "        while True:\n",
    "            x, y = [], []\n",
    "            idx = np.random.choice(self.names, batch_size)\n",
    "            for i in range(idx.shape[0]):\n",
    "                x.append(self.image_loader(images_dir + idx[i]))\n",
    "                y.append(self.image_loader(labels_dir + idx[i]))\n",
    "            yield torch.stack(x), torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        # Convolution layers\n",
    "        \n",
    "        # input is (nc) x 256 x 256\n",
    "        self.conv1 = nn.Conv2d(nc, ngf, 4, 2, 1, bias=True)\n",
    "        self.lr1 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf) x 128 x 128\n",
    "        self.conv2 = nn.Conv2d(ngf, ngf*2, 4, 2, 1, bias=True)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf*2)\n",
    "        self.lr2 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*2) x 64 x 64\n",
    "        self.conv3 = nn.Conv2d(ngf*2, ngf*4, 4, 2, 1, bias=True)\n",
    "        self.bn3 = nn.BatchNorm2d(ngf*4)\n",
    "        self.lr3 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*4) x 32 x 32\n",
    "        self.conv4 = nn.Conv2d(ngf*4, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn4 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr4 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 16 x 16\n",
    "        self.conv5 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn5 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr5 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 8 x 8\n",
    "        self.conv6 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn6 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr6 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 4 x 4\n",
    "        self.conv7 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn7 = nn.BatchNorm2d(ngf*8)\n",
    "        self.lr7 = nn.LeakyReLU(inplace=True)\n",
    "        # state size. (ngf*8) x 2 x 2\n",
    "        self.conv8 = nn.Conv2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.bn8 = nn.BatchNorm2d(ngf*8)\n",
    "        self.r8 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # Transpose Convolutional Layers\n",
    "        \n",
    "        # input is (ngf*8) x 1 x 1\n",
    "        self.tr_conv1 = nn.ConvTranspose2d(ngf*8, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn1 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r1 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 2 x 2\n",
    "        self.tr_conv2 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn2 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r2 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 4 x 4\n",
    "        self.tr_conv3 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn3 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r3 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 8 x 8\n",
    "        self.tr_conv4 = nn.ConvTranspose2d((ngf*8)*2, ngf*8, 4, 2, 1, bias=True)\n",
    "        self.tr_bn4 = nn.BatchNorm2d(ngf*8)\n",
    "        self.tr_r4 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*8)*2 x 16 x 16\n",
    "        self.tr_conv5 = nn.ConvTranspose2d((ngf*8)*2, ngf*4, 4, 2, 1, bias=True)\n",
    "        self.tr_bn5 = nn.BatchNorm2d(ngf*4)\n",
    "        self.tr_r5 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*4)*2 x 32 x 32\n",
    "        self.tr_conv6 = nn.ConvTranspose2d((ngf*4)*2, ngf*2, 4, 2, 1, bias=True)\n",
    "        self.tr_bn6 = nn.BatchNorm2d(ngf*2)\n",
    "        self.tr_r6 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf*2)*2 x 64 x 64\n",
    "        self.tr_conv7 = nn.ConvTranspose2d((ngf*2)*2, ngf, 4, 2, 1, bias=True)\n",
    "        self.tr_bn7 = nn.BatchNorm2d(ngf)\n",
    "        self.tr_r7 = nn.ReLU(inplace=True)\n",
    "        # state size. (ngf)*2 x 128 x 128\n",
    "        self.tr_conv8 = nn.ConvTranspose2d((ngf)*2, nc, 4, 2, 1, bias=True)\n",
    "        self.out = nn.Tanh()\n",
    "        # state size. (nc) x 256 x 256\n",
    "    \n",
    "    def forward(self, x):\n",
    "        c1 = self.conv1(x)\n",
    "        c2 = self.bn2(self.conv2(self.lr1(c1)))\n",
    "        c3 = self.bn3(self.conv3(self.lr2(c2)))\n",
    "        c4 = self.bn4(self.conv4(self.lr3(c3)))\n",
    "        c5 = self.bn5(self.conv5(self.lr4(c4)))\n",
    "        c6 = self.bn6(self.conv6(self.lr5(c5)))\n",
    "        c7 = self.bn7(self.conv7(self.lr6(c6)))\n",
    "        c8 = self.bn8(self.conv8(self.lr7(c7)))\n",
    "        \n",
    "        t1 = self.tr_bn1(self.tr_conv1(self.r8(c8)))\n",
    "        t1 = torch.cat((t1, c7), dim=1)\n",
    "        t2 = self.tr_bn2(self.tr_conv2(self.tr_r1(t1)))\n",
    "        t2 = torch.cat((t2, c6), dim=1)\n",
    "        t3 = self.tr_bn3(self.tr_conv3(self.tr_r2(t2)))\n",
    "        t3 = torch.cat((t3, c5), dim=1)\n",
    "        t4 = self.tr_bn4(self.tr_conv4(self.tr_r3(t3)))\n",
    "        t4 = torch.cat((t4, c4), dim=1)\n",
    "        t5 = self.tr_bn5(self.tr_conv5(self.tr_r4(t4)))\n",
    "        t5 = torch.cat((t5, c3), dim=1)\n",
    "        t6 = self.tr_bn6(self.tr_conv6(self.tr_r5(t5)))\n",
    "        t6 = torch.cat((t6, c2), dim=1)\n",
    "        t7 = self.tr_bn7(self.tr_conv7(self.tr_r6(t6)))\n",
    "        t7 = torch.cat((t7, c1), dim=1)\n",
    "        t8 = self.tr_conv8(self.tr_r7(t7))\n",
    "        t8 = self.out(t8)\n",
    "        return t8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_a = Generator().to(device)\n",
    "gen_b = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # input is (nc) x 256 x 256\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 128 x 128\n",
    "            nn.MaxPool2d((2, 2)), \n",
    "            \n",
    "            # state size. (ndf) x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. 32 x 32\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "    \n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, ndf * 8, 4, 2, 1, bias=True),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            )\n",
    "        \n",
    "        self.flat = nn.Linear(ndf * 8 * 2 * 2, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.flat(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_a = Discriminator().to(device)\n",
    "dis_b = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (6): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (10): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): LeakyReLU(negative_slope=0.2, inplace)\n",
       "    (13): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (14): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (15): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  )\n",
       "  (flat): Linear(in_features=2048, out_features=1, bias=True)\n",
       "  (out): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataParallel for more than 1 gpu\n",
    "# gen_a = nn.DataParallel(gen_a, list(range(ngpu)))\n",
    "# dis_a = nn.DataParallel(dis_a, list(range(ngpu)))\n",
    "# gen_b = nn.DataParallel(gen_b, list(range(ngpu)))\n",
    "# dis_b = nn.DataParallel(dis_b, list(range(ngpu)))\n",
    "\n",
    "gen_a.apply(weights_init_normal)\n",
    "dis_a.apply(weights_init_normal)\n",
    "gen_b.apply(weights_init_normal)\n",
    "dis_b.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "optim_gen_a = torch.optim.RMSprop(gen_a.parameters(), lr, alpha)\n",
    "optim_gen_b = torch.optim.RMSprop(gen_b.parameters(), lr, alpha)\n",
    "optim_dis_a = torch.optim.RMSprop(dis_a.parameters(), lr, alpha)\n",
    "optim_dis_b = torch.optim.RMSprop(dis_b.parameters(), lr, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_interval = 25\n",
    "checkpoint_interval = 500\n",
    "\n",
    "prev_load = 0\n",
    "if(prev_load):\n",
    "    gen_a.load_state_dict(torch.load(proj_root + 'saved_models/dual_gans/generator_a_1_1000.pth'))\n",
    "    dis_a.load_state_dict(torch.load(proj_root + 'saved_models/dual_gans/discriminator_a_1_1000.pth'))\n",
    "    gen_b.load_state_dict(torch.load(proj_root + 'saved_models/dual_gans/generator_b_1_1000.pth'))\n",
    "    dis_b.load_state_dict(torch.load(proj_root + 'saved_models/dual_gans/discriminator_b_1_1000.pth'))\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(num_images // batch_size):\n",
    "        x, y = next(data.data_generator())\n",
    "        real_a = Variable(x).to(device)\n",
    "        real_b = Variable(y).to(device)     \n",
    "        valid = Variable(torch.ones((real_a.size(0), 1)), requires_grad=False).to(device)\n",
    "        fake = Variable(torch.zeros((real_a.size(0), 1)), requires_grad=False).to(device)\n",
    "        \n",
    "        # Training Discriminator A with real_A batch\n",
    "        optim_dis_a.zero_grad();\n",
    "        pred_real_dis_a = dis_a(real_a).view(-1, 1)\n",
    "        err_real_dis_a = criterion(pred_real_dis_a, valid)\n",
    "        err_real_dis_a.backward()\n",
    "        \n",
    "        # Training Discriminator B with real_B batch\n",
    "        optim_dis_b.zero_grad();\n",
    "        pred_real_dis_b = dis_b(real_b).view(-1, 1)\n",
    "        err_real_dis_b = criterion(pred_real_dis_b, valid)\n",
    "        err_real_dis_b.backward()\n",
    "        \n",
    "        # Training Discriminator B with fake_B batch of Generator A\n",
    "        fake_b = gen_a(real_a)\n",
    "        pred_fake_dis_b = dis_b(fake_b.detach()).view(-1, 1)\n",
    "        err_fake_dis_b = criterion(pred_fake_dis_b, fake)\n",
    "        err_fake_dis_b.backward()\n",
    "        \n",
    "        # Training Discriminator A with fake_A batch of Generator B\n",
    "        fake_a = gen_b(real_b)\n",
    "        pred_fake_dis_a = dis_a(fake_a.detach()).view(-1, 1)\n",
    "        err_fake_dis_a = criterion(pred_fake_dis_a, fake)\n",
    "        err_fake_dis_a.backward()\n",
    "        \n",
    "        # Update params of Discriminator A and B\n",
    "        err_dis_a = err_real_dis_a + err_fake_dis_a\n",
    "        optim_dis_a.step()\n",
    "        err_dis_b = err_real_dis_b + err_fake_dis_b\n",
    "        optim_dis_b.step()\n",
    "        \n",
    "        # Train and update Generator A based on Discriminator B's prediction\n",
    "        optim_gen_a.zero_grad()\n",
    "        pred_out_dis_b = dis_b(fake_b).view(-1, 1)\n",
    "        err_gen_a = criterion(pred_out_dis_b, valid)\n",
    "        err_gen_a.backward()\n",
    "        optim_gen_a.step()\n",
    "        \n",
    "        # Train and update Generator B based on Discriminator A's prediction\n",
    "        optim_gen_b.zero_grad()\n",
    "        pred_out_dis_a = dis_a(fake_a).view(-1, 1)\n",
    "        err_gen_b = criterion(pred_out_dis_a, valid)\n",
    "        err_gen_b.backward()\n",
    "        optim_gen_b.step()\n",
    "        \n",
    "        # Print statistics and save checkpoints\n",
    "        print(\"\\r[Epoch %d/%d] [Batch %d/%d] [D_A loss: %f] [D_B loss: %f] [G_A loss: %f, G_B loss: %f]\" %\n",
    "                                                        (epoch, num_epochs,\n",
    "                                                        i, num_images//batch_size,\n",
    "                                                        err_dis_a.item(), err_dis_b.item(), \n",
    "                                                        err_gen_a.item(), err_gen_b.item()))\n",
    "\n",
    "        if i % sample_interval == 0:\n",
    "            img_sample = torch.cat((real_a.data, fake_a.data, real_b.data, fake_b.data), -2)\n",
    "            save_image(img_sample, proj_root + 'saved_images/dual_gans/%d_%d.png' % (epoch, i), nrow=5, normalize=True)\n",
    "\n",
    "\n",
    "        if i % checkpoint_interval == 0:\n",
    "            torch.save(gen_a.state_dict(), proj_root + 'saved_models/dual_gans/generator_a_%d_%d.pth' % (epoch, i))\n",
    "            torch.save(gen_b.state_dict(), proj_root + 'saved_models/dual_gans/generator_b_%d_%d.pth' % (epoch, i))\n",
    "            torch.save(dis_a.state_dict(), proj_root + 'saved_models/dual_gans/discriminator_a_%d_%d.pth' % (epoch, i))\n",
    "            torch.save(dis_b.state_dict(), proj_root + 'saved_models/dual_gans/discriminator_b_%d_%d.pth' % (epoch, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
